{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408c4bca",
   "metadata": {},
   "source": [
    "# Rendu de TD Reconnaissances d'entités nommées avec une approche transformers \n",
    "\n",
    "Alexis Mérienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd60de",
   "metadata": {},
   "source": [
    "### Les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4701838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset,DatasetDict\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d24cce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d51df0",
   "metadata": {},
   "source": [
    "## I. Preprocessing\n",
    "\n",
    "### I.a Le dataset\n",
    "\n",
    "\n",
    "Le dataset est composée de phrases en anglais pour lesquelles certains mots sont labélisés. \n",
    "\n",
    "Les labels sont :\n",
    "\n",
    " * personnes (**PER**), \n",
    " * lieux (**LOC**) \n",
    " * organisations (**ORG**)\n",
    " * autres (**O**)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bbd2ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Le fichier texte contenant les données est structuré de la sorte :\n",
    "\n",
    "- Une ligne contient un mot ainsi que ces labels\n",
    "- Les phrases sont séparées d'une ligne blanche\n",
    "\n",
    "ex : \n",
    "\n",
    "EU NNP B-NP B-ORG\n",
    "rejects VBZ B-VP O\n",
    "German JJ B-NP B-MISC\n",
    "call NN I-NP O\n",
    "to TO B-VP O\n",
    "boycott VB I-VP O\n",
    "British JJ B-NP B-MISC\n",
    "lamb NN I-NP O\n",
    ". . O O\n",
    "\n",
    "\n",
    "_read_dataset lit le dataset en paramètre et stocke les phrases dans une liste, sous la forme d'un tuple (mots,position_tag,ner_tag)\n",
    "'''\n",
    "def _read_dataset(filepath):\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            sents = {\n",
    "                \"sentences\" : [],\n",
    "                \"ner_tags\" : []\n",
    "            }\n",
    "            sent = []\n",
    "            ner_tags = []\n",
    "            for line in f:\n",
    "                if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
    "                   \n",
    "                    sents[\"sentences\"].append(sent)\n",
    "                    sents[\"ner_tags\"].append(ner_tags)\n",
    "                    sent = []\n",
    "                    ner_tags = []\n",
    "                else:\n",
    "                    splits = line.split(\" \")\n",
    "                    token = splits[0]\n",
    "                    pos_tag = splits[1]\n",
    "                    ner_tag = splits[3].rstrip()\n",
    "                    if 'MISC' in ner_tag:\n",
    "                        ner_tag = 'O'\n",
    "                    \n",
    "                    sent.append(token)\n",
    "                    ner_tags.append(ner_tag)\n",
    "        return sents               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7dd1b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = _read_dataset('NER Dataset/train.txt')\n",
    "validation_sents = _read_dataset('NER Dataset/test.txt')\n",
    "\n",
    "train_sentences = train_sents[\"sentences\"]\n",
    "train_ner_tags = train_sents[\"ner_tags\"]\n",
    "n_train = len(train_ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "530fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = validation_sents[\"sentences\"]\n",
    "test_ner_tags = validation_sents[\"ner_tags\"]\n",
    "n_test = len(test_ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717bf73",
   "metadata": {},
   "source": [
    "### I.B Les tags de reconnaissance d'entités nommées\n",
    "\n",
    "Dans cette partie, nous nous intéressons à convertir les tags NER en id numérique. Cette étape est importante car pour la tokenisation des inputs du modèle, le format des données d'entrées des tags NER sont des entiers, représentant leur ids.\n",
    "\n",
    "Ainsi, la solution que nous avons choisi dans ce notebook est d'ajouter une *key* dans les dictionnaires des données d'entrées contenant les labels sous format d'entiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "badb6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ner_tags = []\n",
    "for s in ner_tags:\n",
    "    for t in s:\n",
    "        all_ner_tags.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a319e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-ORG', 'B-ORG', 'B-LOC', 'O', 'I-PER', 'B-PER', 'I-LOC']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = list(set(all_ner_tags))\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "467e989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertit les labels NER en id\n",
    "label2id = {label:i for i, label in enumerate(label_names)}\n",
    "#Nous verrons par la suite à quoi sert le tag \"SEP/CLS\", qui n'est pas encore présent dans nos données\n",
    "label2id[\"SEP/CLS\"] = -100\n",
    "\n",
    "#convertit les id en labels\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "nb_labels = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "355094b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-ORG': 0,\n",
       " 'B-ORG': 1,\n",
       " 'B-LOC': 2,\n",
       " 'O': 3,\n",
       " 'I-PER': 4,\n",
       " 'B-PER': 5,\n",
       " 'I-LOC': 6,\n",
       " 'SEP/CLS': -100}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "927148fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renvoie la liste d'id de la liste de labels NER donné en paramètre\n",
    "def convert_tag_to_label(ner_tags):\n",
    "    labels=[]\n",
    "    for el in ner_tags:\n",
    "        labels.append(label2id[el])\n",
    "        \n",
    "    return labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "330874cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " [1, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On construit la liste des ids pour les données d'entrainement. \n",
    "train_labels = []\n",
    "for tag in train_ner_tags:\n",
    "    train_labels.append(convert_tag_to_label(tag))\n",
    "train_ner_tags[2],train_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ba642858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On construit la liste des ids pour les données de test. \n",
    "test_labels = []\n",
    "for tag in val_ner_tags:\n",
    "    test_labels.append(convert_tag_to_label(tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882f61c",
   "metadata": {},
   "source": [
    "### I.C Construction du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c823a8",
   "metadata": {},
   "source": [
    "Ici, on convertit nos données sous la forme de dictionnaires dont les attributs sont \"sentences\", qui sont la liste des phrases présentes dans le dataset, \"ner_tags\", les tags associés à ces phraseset labels, les ids de ces tags. \n",
    "\n",
    "On divise en ensuite les données d'entrainements en deux jeu de données : \n",
    "\n",
    "        - Les données sur lesquelles le modèles va apprendre\n",
    "        - Les données de validation\n",
    "        \n",
    "Le ratio de cette division est 80% pour les données d'entrainement, 20% pour les données de validation. Ce choix provient du fait que ce ratio est plus présent dans la littérature. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1f87efbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
       "      <td>[B-ORG, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Peter, Blackburn]</td>\n",
       "      <td>[B-PER, I-PER]</td>\n",
       "      <td>[5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[BRUSSELS, 1996-08-22]</td>\n",
       "      <td>[B-LOC, O]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
       "      <td>[O, B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
       "      <td>[B-LOC, O, O, O, O, B-ORG, I-ORG, O, O, O, B-P...</td>\n",
       "      <td>[2, 3, 3, 3, 3, 1, 0, 3, 3, 3, 5, 4, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "2  [EU, rejects, German, call, to, boycott, Briti...   \n",
       "3                                 [Peter, Blackburn]   \n",
       "4                             [BRUSSELS, 1996-08-22]   \n",
       "5  [The, European, Commission, said, on, Thursday...   \n",
       "6  [Germany, 's, representative, to, the, Europea...   \n",
       "\n",
       "                                            ner_tags  \\\n",
       "2                    [B-ORG, O, O, O, O, O, O, O, O]   \n",
       "3                                     [B-PER, I-PER]   \n",
       "4                                         [B-LOC, O]   \n",
       "5  [O, B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O...   \n",
       "6  [B-LOC, O, O, O, O, B-ORG, I-ORG, O, O, O, B-P...   \n",
       "\n",
       "                                              labels  \n",
       "2                        [1, 3, 3, 3, 3, 3, 3, 3, 3]  \n",
       "3                                             [5, 4]  \n",
       "4                                             [2, 3]  \n",
       "5  [3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "6  [2, 3, 3, 3, 3, 1, 0, 3, 3, 3, 5, 4, 3, 3, 3, ...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://huggingface.co/docs/datasets/tabular_load\n",
    "\n",
    "df_train = pd.DataFrame({\"sentences\":train_sentences,\"ner_tags\":train_ner_tags,\"labels\":train_labels})\n",
    "#df_train = df.drop([0,1])\n",
    "\n",
    "df_test = pd.DataFrame({\"sentences\":test_sentences,\"ner_tags\":test_ner_tags,\"labels\":test_labels})\n",
    "#df_val = df.drop([0,1])\n",
    "\n",
    "df_train=df_train.drop([0,1])\n",
    "df_test=df_test.drop([0,1])\n",
    "\n",
    "df_train, df_val = np.array_split(\n",
    "    df_train, (np.array([0.8,0.2])[:-1].cumsum() * len(df_train)).astype(int))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "10905dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentences', 'ner_tags', 'labels'],\n",
       "        num_rows: 12744\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentences', 'ner_tags', 'labels'],\n",
       "        num_rows: 3186\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'ner_tags', 'labels'],\n",
       "        num_rows: 3912\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On construit ensuite le dataset, composé de nos 3 jeu de données : train, validation, test\n",
    "ner_dataset_train = Dataset.from_pandas(df_train)\n",
    "ner_dataset_validation = Dataset.from_pandas(df_val) \n",
    "ner_dataset_test = Dataset.from_pandas(df_test)\n",
    "ner_dataset = DatasetDict({\"train\":ner_dataset_train,\"validation\":ner_dataset_validation,\"test\":ner_dataset_test})\n",
    "ner_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8f48df4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[\"train\"][0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3c8aaaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[\"train\"][0][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d038a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Début d'un nouveau mot\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Token de séparation\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Même mot que le token précédent\n",
    "            label = labels[word_id]\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ccf9fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[-100, 1, 3, 3, 3, 3, 3, 3, 3, 3, -100]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(ner_dataset[\"train\"][0][\"sentences\"], is_split_into_words=True)\n",
    "inputs.tokens()\n",
    "\n",
    "labels = ner_dataset[\"train\"][0][\"labels\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed16eb",
   "metadata": {},
   "source": [
    "### I.D Tokenizer\n",
    "\n",
    "On crée une fonction que l'on appelle dans le tokenizer pour aligner les ids des labels NER avec les phrases. \n",
    "\n",
    "La tokenisation est une étape cruciale de notre pipeline de données. En effet, elle nous permet de traduire le texte en données intérprétable par le modèle. \n",
    "\n",
    "Les librairie transformer proposent des tokenizers pré-entrainé sur le modèle choisit. Nous utilisons ici celui de \"distilbert-base-uncased\". Sa fonction est de construire un mapping entre les mots en anglais et des ids corresondants.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fee95b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentences\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "13d3651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03207898139953613,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4646a56526db4f6c8d5a24f4f4a49df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01599740982055664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae5190db2414e45b31c0d346a2146ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0159914493560791,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f491ac20004aa78575de422101483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = ner_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=ner_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74751d9",
   "metadata": {},
   "source": [
    "## II. Le modèle transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9866a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f022c86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 11), dtype=int64, numpy=\n",
       "array([[-100,    1,    3,    3,    3,    3,    3,    3,    3,    3, -100],\n",
       "       [-100,    5,    4, -100, -100, -100, -100, -100, -100, -100, -100]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On test ici si le data_collector convertit bien les données tokenisées en tenseur. \n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "61dfa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme nos trois jeux de données en tenseur, qui sont des objets intérprétables par le modèle\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0c8885e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForTokenClassification: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_79']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    return_dict=True,           \n",
    "    output_hidden_states=False, \n",
    "    output_attentions=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6c7e10c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9e03bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "797/797 [==============================] - 2526s 3s/step - loss: 0.2055 - val_loss: 0.0891\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 34769s 44s/step - loss: 0.0455 - val_loss: 0.0821\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1933s 2s/step - loss: 0.0289 - val_loss: 0.0828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2278027ed10>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ed588381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'seqeval`'\n"
     ]
    }
   ],
   "source": [
    "#!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ec144cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "all_pred = []\n",
    "all_true = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        p_ = []\n",
    "        t_ = []\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == label2id[\"SEP/CLS\"]:\n",
    "                continue\n",
    "            p_.append(label_names[predicted_idx])\n",
    "            t_.append(label_names[label_idx])\n",
    "        all_pred.append(p_)\n",
    "        all_true.append(t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f11fbdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.94      0.91      0.92      3908\n",
      "         ORG       0.87      0.83      0.85      1846\n",
      "         PER       0.95      0.96      0.96      5745\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     11499\n",
      "   macro avg       0.92      0.90      0.91     11499\n",
      "weighted avg       0.93      0.92      0.93     11499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_pred, all_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbe871",
   "metadata": {},
   "source": [
    "## III. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ebafda4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Les données 'baseline', 'RNN' et 'attention' proviennent des approches étudiés lors du rendu précédent. \n",
    "result = {\n",
    "    \"baseline\" : [0.150,0.047,0.049,0.246],\n",
    "    \"RNN\" : [0.584,0.690, 0.551, 0.645],\n",
    "    \"attention\" :  [0.651,0.781, 0.636, 0.640],\n",
    "    \"transformers\": [0.93,0.92,0.96,0.85]\n",
    "}\n",
    "\n",
    "index = ['f1-weight avg', 'f1-LOC', 'f1-PER','f1-ORG']\n",
    "\n",
    "df = pd.DataFrame(result, index=index)\n",
    "ax = df.plot.bar(rot=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
